{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48536913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import re\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6386dba",
   "metadata": {},
   "source": [
    "# Load data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc4a93de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentence = pd.read_pickle('../dataset/SS/clean/sentence_data.pkl')\n",
    "\n",
    "sentence_corpus = {}\n",
    "for d in df_sentence:\n",
    "    sentence_corpus.update(d)\n",
    "    \n",
    "corpus = pd.read_pickle('../dataset/SS/clean/SPECTER_embeddings.pkl')\n",
    "kmeans_5 = joblib.load('../model/kmeans_5_specter.model')\n",
    "pca = joblib.load('../model/pca.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a308d80",
   "metadata": {},
   "source": [
    "# Workflow\n",
    "### paper -> embedding -> pca -> kmeans -> cluster_label -> choose model -> recommend citations -> get sentences -> process sentences -> generate related work section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5ec9189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get embedding\n",
    "embedding = corpus.loc['42490916', 'SPECTER_embeddings'].reshape(1, -1)\n",
    "\n",
    "# PCA transform\n",
    "vec = pca.transform(embedding)\n",
    "\n",
    "# kmeans cluster\n",
    "label = kmeans_5.predict(vec)\n",
    "\n",
    "# choose a model and citation list\n",
    "filename = '../model/model_' + str(label[0]) + '.h5'\n",
    "citename = '../dataset/SS/clean/citation_' + str(label[0]) + '.pkl'\n",
    "\n",
    "model = load_model(filename)\n",
    "df_citation = pd.read_pickle(citename)\n",
    "citations = np.array(df_citation['citation_id'])\n",
    "\n",
    "prediction = model.predict(embedding)[0]\n",
    "recommendation = np.argsort(prediction)[::-1][:20] # recommend 20 possible citations\n",
    "\n",
    "# retrieve sentences and remove cite spans.\n",
    "rw_sentence = []\n",
    "for idx in citations[recommendation]:\n",
    "    s = sentence_corpus.get(idx)\n",
    "    if s is not None:\n",
    "        s = re.sub(r' \\[.*\\]', '', s)\n",
    "        rw_sentence.append(s)\n",
    "        \n",
    "generated_rw = ' '.join(rw_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86c1d2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original citations: \n",
      " ['11864530', '3961724', '16510219', '6485959', '7973738', '425268'] \n",
      "\n",
      "Recommend citations: \n",
      " ['206593071' '425268' '7973738' '3961724' '938105' '14909631' '14997888'\n",
      " '11864530' '6485959' '14124239' '3198903' '9088600' '206595765'\n",
      " '12203312' '15172651' '206590483' '10070153' '14991802' '8964627'\n",
      " '3332134']\n"
     ]
    }
   ],
   "source": [
    "print('Original citations: \\n', corpus.loc['42490916', 'rw_citations'], '\\n')\n",
    "print('Recommend citations: \\n', citations[recommendation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96346360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original related work section: \n",
      "\n",
      "Person Re-identification A lot of methods have been proposed for person re-identification and can be divided into two categories: direct methods and learning based methods. Direct methods focus on feature descriptors or geometric structure to describe pedestrians with no requirements of learning. Farenzena et al. [10] take advantage of the symmetry and asymmetry of human structure and propose Symmetry-Driven Accumulation of Local Features (SDALF) including weighted-HSV histogram, Maximally Stable Color Regions (MSCR), and Recurrent Highly Structured Patches (RHSP). Ma et al. [11] achieve superior performance by combining BiCov descriptor with SDALF to handle illumination change. Cheng et al. [12] utilize Pictorial Structures (PS) to pay attention to body parts and takes advantage of part-to-part correspondence. On the other hand, learning methods always use pre-labled training sets to learn proper features or metric functions [13] , [14] , [24] , [25] , [28] . Adaboost algorithm is first used in [13] to select optimal features among an ensemble of localized features for matching pedestrians. Probabilistic Relative Distance Comparison (PRDC) [14] learns the optimal distance with the criterion that a pair of true match have a smaller distance than that of a wrong match. Zhao et al. [15] propose unsupervised salience learning which obtains the state-of-the-art results by mining salient features.\n"
     ]
    }
   ],
   "source": [
    "print('Original related work section: \\n')\n",
    "print(corpus.loc['42490916', 'relatedwork_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4a14bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated related work section: \n",
      "\n",
      "The first group uses the siamese model with image pairs as inputs. Most existing identity alignment methods focus on supervised learning of person identity-discriminative information. In ) and 3) recurrent highly structured patches (RHSP). Early person re-identification methods focus on manually designing discriminative features . Methods based on Siamese models alone are not a viable solution to our problem, since they need image crops of the object and can not fully utilize re-identification annotations due to their pairwise labelling training setup. Concerning multiple-shot approaches, in the spatiotemporal graph was generated for a ten consecutive frames for grouping spatiotemporally similar regions. The first group uses the siamese model with image pairs as inputs. Early person re-identification methods focus on manually designing discriminative features . Before deep neural networks spring up, there are a great amount of research efforts for designing robust handcraft partitioned features, such as color histograms, local binary patterns, Gabor features, etc.  . With a bag-of-words feature-representation for object detection. Attention mechanisms have been used to capture human part information in recent work . To further improve the retrieval precision, re-ranking strategies are adopted too. Structures of keypoints have also been successful in content-based image retrieval, particularly in works based on visual words where descriptors are quantized into a visual vocabulary using clustering. CNN has been gradually improving the accuracy of person re-id . The perframe features include histogram of pixel intensities, histogram of oriented gradients (HOG) and ConvNet features. Early person re-identification methods focus on manually designing discriminative features . Most existing ReID works focus on training the model without taking the occlusions into considerations. Recently, an efficient high-dimensional reduction method based on feature merging , has achieved good performance but with cheaper computation. An improved triplet loss function was designed , which pulls the instances of the same person closer and simultaneously pushes the instances of different persons farther in the learned feature space.\n"
     ]
    }
   ],
   "source": [
    "print('Generated related work section: \\n')\n",
    "print(generated_rw)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
